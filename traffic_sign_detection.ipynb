{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Detection\n",
    "This notebook implements a CNN model for detecting the traffic signs from the [GTSRB Dataset](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign) which consists of 43 classes and around 50,000 images (train+test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "We will read three csv files `Meta.csv`, `Train.csv`, `Test.csv` and explore each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/'\n",
    "# train_path = data_path + 'Train/'\n",
    "# test_path = data_path + 'Test/'\n",
    "df_meta = pd.read_csv(r\"D:\\Akash\\Codes\\Projects\\Traffic_Sign_Detection\\Data\\Meta.csv\")\n",
    "df_train = pd.read_csv(r\"D:\\Akash\\Codes\\Projects\\Traffic_Sign_Detection\\Data\\Train.csv\")\n",
    "df_test = pd.read_csv(r\"D:\\Akash\\Codes\\Projects\\Traffic_Sign_Detection\\Data\\Test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Meta Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four columns in df_meta. `Path`, `ClassId`, `ShapeId`, `ColorId`, `SignId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min. Class Label: {}\".format(df_meta.ClassId.min()))\n",
    "print(\"Max Class Label: {}\".format(df_meta.ClassId.max()))\n",
    "print(\"Total Class Labels: {}\".format(len(df_meta.ClassId.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us visualize all 43 class types** using the coloumn `ClassId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(df_meta.ClassId.unique())\n",
    "class_dict = {}\n",
    "class_labels = list(range(num_classes))\n",
    "# Speed Class 0-9\n",
    "speed_class = ['Speed Limit ' + item for item in [speed + ' kmph' for speed in ['20', '30', '50', '60', '70', '80']]]\\\n",
    "            + ['End of Speed Limit 80 kmph']\n",
    "speed_class+= ['Speed Limit ' + item for item in [speed + ' kmph' for speed in ['100', '120']]]\n",
    "speed_class\n",
    "# 10, 11 No Passing\n",
    "no_pass = ['No Passing' + item for item in ['', ' vehicle over 3.5 ton']]\n",
    "# 12-43\n",
    "rest = ['Right-of-way at intersection', 'Priority road', 'Yield', 'Stop', 'No vehicles', 'Veh > 3.5 tons prohibited',\\\n",
    "            'No entry', 'General caution', 'Dangerous curve left', 'Dangerous curve right', 'Double curve', 'Bumpy road',\n",
    "            'Slippery road', 'Road narrows on the right', 'Road work', 'Traffic signals', 'Pedestrians', 'Children crossing',\n",
    "            'Bicycles crossing', 'Beware of ice/snow','Wild animals crossing', 'End speed + passing limits', 'Turn right ahead',\n",
    "            'Turn left ahead', 'Ahead only', 'Go straight or right', 'Go straight or left', 'Keep right', 'Keep left',\n",
    "            'Roundabout mandatory', 'End of no passing', 'End no passing vehicle > 3.5 tons']\n",
    "class_values = speed_class + no_pass + rest\n",
    "class_dict = {keys:values for keys,values in zip(class_labels, class_values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortFunction = lambda x: int(os.path.basename(x)[:-4])\n",
    "plt.figure(figsize = (25, 25))\n",
    "for i, imagename in enumerate(sorted(glob.glob(data_path + 'Meta/' + '*.*'), key = sortFunction)):\n",
    "    plt.subplot(7, 7, i + 1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(class_dict[i])\n",
    "    image = cv2.imread(imagename)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us visualize the shapes and colors of the sign** using the columns `ShapeId` and `ColorId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_dict = {0: 'Triangle', 1: 'Circle', 2: 'Diamond', 3: 'Hexagon', 4: 'Inverse Triangle'}\n",
    "df_meta.ShapeId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_shape(shape = 0):\n",
    "    \"\"\"\n",
    "    Plots random samples of a particular shape from shape_dict\n",
    "    \"\"\"\n",
    "    filenames = df_meta[df_meta.ShapeId==shape].sample(10).Path\n",
    "    plt.figure(figsize = (25, 25))\n",
    "    for i, filename in enumerate(data_path + filenames):\n",
    "        image = cv2.imread(filename)\n",
    "        plt.subplot(11, 4, i+1)\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Triangular signs, ShapeId=0\n",
    "visualize_shape(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {0:'Red', 1:'Blue', 2:'Yellow', 3:'White'}\n",
    "df_meta.ColorId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_color(color = 0):\n",
    "    \"\"\"\n",
    "    Plots random samples of a particular color from color_dict\n",
    "    \"\"\"\n",
    "    filenames = df_meta[df_meta.ColorId==color].sample(5).Path\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    for i, filename in enumerate(data_path + filenames):\n",
    "        image = cv2.imread(filename)\n",
    "        plt.subplot(1, 6, i+1)\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Blue Colored Traffic Signs, color = 1\n",
    "visualize_color(color = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Train Dataframe\n",
    "1. Check the shape of the train dataframe\n",
    "2. Check the description of all features\n",
    "3. Create a dictionary `train_dict` with labels as keys and value_counts as values\n",
    "4. Plot the Class Distribution of Training data\n",
    "5. Check if the folder directory information is consistent and create the same dictionary `train_sample_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.ClassId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary which consists of the labels as keys and the number of samples as values\n",
    "train_dict = {}\n",
    "train_dict = {keys:values for keys,values in zip(df_train.ClassId.value_counts().index, df_train.ClassId.value_counts().tolist())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (21 ,11))\n",
    "plt.bar(train_dict.keys(), train_dict.values())\n",
    "plt.title('Class Distribution for Training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframe information with folder directory\n",
    "train_folders = os.listdir(train_path)\n",
    "# Create a dict with keys as label names and the number of images present inside each label folder as values\n",
    "sample_dict = {}\n",
    "for folders in train_folders:\n",
    "    images = os.listdir(train_path + folders)\n",
    "    sample_dict[folders] = len(images)\n",
    "train_sample_dict = {int(k):v for k,v in zip(sample_dict.keys(), sample_dict.values())}\n",
    "train_dict==train_sample_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataframe\n",
    "1. Check the shape of the test dataframe\n",
    "2. Check the description of all features\n",
    "3. Create a dictionary `test_dict` with labels as keys and value_counts as values\n",
    "4. Plot the Class Distribution of Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.ClassId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test_dict with keys as the labels and values as the value_counts\n",
    "test_dict = {}\n",
    "test_dict = {keys:values for keys,values in zip(df_test.ClassId.value_counts().index, df_test.ClassId.value_counts().tolist())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (21, 11))\n",
    "plt.bar(test_dict.keys(), test_dict.values())\n",
    "plt.title(\"Class Distribution of Test Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data Balance\n",
    "When we see the individual training and testing class distributions the dataset might seem imbalanced. So we want to check this for each label, by measuring the label-wise train test ratio. This will be important while training the model because when we split the training data into `train` and `validation` we would like to retain the ratio of both sets for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance = pd.DataFrame()\n",
    "df_balance['labels'] = list(range(43))\n",
    "df_balance['train'] = train_dict.values()\n",
    "df_balance['test'] = test_dict.values()\n",
    "df_balance['total'] = df_balance['train'] + df_balance['test']\n",
    "df_balance['train_ratio'] = df_balance['train']/df_balance['total']\n",
    "df_balance['test_ratio'] = df_balance['test']/df_balance['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check train test ratio for the first 10 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_balance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the train test ratio for each label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance.plot(x = 'labels', y = ['train_ratio', 'test_ratio'], kind = 'bar', figsize = (21, 11), title = \"Train Test Ratio for each class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that the data is not that imbalanced when we check labelwise distribution, so data balancing is not required**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Duplicate Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Path.duplicated().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.Path.duplicated().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No duplicate entries found in train and test csv files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "After an extensive EDA, we will prepare our dataset from the `data/Train` and `data/Test`. The `Train` folder consists of 43 folders from `0` to `42`. Each folder consists of images. So we will prepare our training data by iterating over thse folders.\n",
    "\n",
    "For the `Test` data, the folder consists of only images and the `ground-truth` is given in the dataframe `df_test`, we need to predict the labels for each of these images\n",
    "\n",
    "Before training the model, we will split the `Train` dataset into `train` and `val` using 80-20 stratified split to retain the ratio of balance. `train` and `test` datasets are already in an approximate split of 75-25. This will lead to an overall split of:\n",
    "\n",
    "- `Train` 60%\n",
    "- `Val` 15%\n",
    "- `Test` 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "1. Iterate over all folders to get images and labels\n",
    "2. Store the data in `train_data` and labels in `train_labels`\n",
    "3. Check whether the length of both arrays is equal to the information provided in `df_train`\n",
    "4. Split the training data into 2 sets `train` and `val` for training using `stratified train-test split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for folders in tqdm.tqdm(train_folders):\n",
    "    imagefiles = os.listdir(train_path + folders)\n",
    "    for imagefile in imagefiles:\n",
    "        path = os.path.join(train_path, folders, imagefile)\n",
    "        image = Image.open(path)\n",
    "        image = image.resize((32, 32))\n",
    "        image = np.array(image)\n",
    "        train_data.append(image)\n",
    "        train_labels.append(int(folders))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of both arrays\n",
    "len(df_train), len(train_data), len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The number of images in the train folders are equivalent to the samples given in dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"There are {} images in train dataset\".format(len(train_data)))\n",
    "print(\"Each image has a dimension of : {}\".format(train_data[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Val Split\n",
    "Use the stratified train-test split which retains the class distribution even after splitting in 80-20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size = 0.2, stratify = train_labels, random_state = 42)\n",
    "train_unique, y_train_count = np.unique(y_train, return_counts = True)\n",
    "val_unique, y_val_count = np.unique(y_val, return_counts = True)\n",
    "y_train, y_val = to_categorical(y_train, num_classes), to_categorical(y_val, num_classes)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (21, 11))\n",
    "plt.bar(train_unique, y_train_count)\n",
    "plt.bar(val_unique, y_val_count)\n",
    "plt.legend(['Train Split', 'Val Split'], loc = 'upper right')\n",
    "plt.title(\"After Splitting into Train and Val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "1. Iterate over the test directory over all images\n",
    "2. Store the images in `test_data`\n",
    "3. Ground truth predictions are given in `df_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_ground_truth = df_test.ClassId.tolist()\n",
    "test_filenames = (data_path + df_test.Path).tolist()\n",
    "for test_filename in tqdm.tqdm(test_filenames):\n",
    "    image_filename = Image.open(test_filename)\n",
    "    image = image_filename.resize((32, 32))\n",
    "    image = np.array(image)\n",
    "    test_data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(test_data)\n",
    "y_test = np.array(test_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unique, y_test_count = np.unique(y_test, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Val-Test Split\n",
    "Visualize the distribution of training, validation and testing data after splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance['val'] = y_val_count\n",
    "df_balance['val_ratio'] = df_balance['val']/df_balance['total']\n",
    "df_balance['train_ratio'] = df_balance['train_ratio'] - df_balance['val_ratio']\n",
    "df_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance.plot.bar(x = 'labels', y = ['train', 'test', 'val'], figsize = (25, 25), stacked = True, title = \"Train Val Test Split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model\n",
    "We will now build a CNN model for training using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(43, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model\n",
    "Fit the model using training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = X_train/255., X_val/255., X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['acc'], label = \"Training Accuracy\")\n",
    "plt.plot(history.history['val_acc'], label = \"Validation Accuracy\")\n",
    "plt.title(\"Accuracy Plot\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label = \"Training Loss\")\n",
    "plt.plot(history.history['val_loss'], label = \"Validation Loss\")\n",
    "plt.title(\"Loss Plot\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "cfm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cfm = pd.DataFrame(cfm, index = [i for i in range(num_classes)], columns = [i for i in range(num_classes)])\n",
    "plt.figure(figsize = (25, 25))\n",
    "sns.heatmap(df_cfm, annot=True, cmap=sns.cubehelix_palette(as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30, 30))\n",
    "start_index = 36\n",
    "for i in range(30):\n",
    "    plt.subplot(10, 3, i + 1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    prediction = predictions[start_index + i]\n",
    "    ground_truth = y_test[start_index + i]\n",
    "    col = 'g'\n",
    "    if prediction != ground_truth:\n",
    "        col = 'r'\n",
    "    plt.xlabel('Actual Class {} , Predicted Class {}'.format(class_dict[ground_truth], class_dict[prediction]), color = col, weight = 'bold')\n",
    "    plt.imshow(X_test[start_index + i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for further implementation\n",
    "os.mkdir('models')\n",
    "model.save('models/traffic_sign_detection_gtsrb.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "1. Use this model and custom dataset to run inference on video using an object detection framework\n",
    "2. Implement OCR capability for non English speaking countries\n",
    "3. Create an interactive dashboard with labelling\n",
    "4. Deploy this model on Streamlit "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
